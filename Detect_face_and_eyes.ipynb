{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97a7693d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a740a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save xml paths\n",
    "face_cascade_name = r'haarcascade_frontalface_alt.xml'\n",
    "eyes_cascade_name = r'haarcascade_eye.xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f819e8fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     ret, frame \u001b[38;5;241m=\u001b[39m capture_cam_img\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m---> 15\u001b[0m     \u001b[43mdetect_face_eye\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;66;03m#shut down cv video sensing when ESC is pressed\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m10\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m27\u001b[39m:\n",
      "Cell \u001b[1;32mIn[3], line 5\u001b[0m, in \u001b[0;36mdetect_face_eye\u001b[1;34m(frame)\u001b[0m\n\u001b[0;32m      3\u001b[0m frame_to_gray \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mequalizeHist(cv2\u001b[38;5;241m.\u001b[39mcvtColor(frame,cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY))\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# application should be able to different scales of images\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m detected_faces \u001b[38;5;241m=\u001b[39m \u001b[43mface_cascade\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetectMultiScale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe_to_gray\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m(x,y,w,h) \u001b[38;5;129;01min\u001b[39;00m detected_faces:\n\u001b[0;32m      7\u001b[0m     center_face\u001b[38;5;241m=\u001b[39m (x \u001b[38;5;241m+\u001b[39m w\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m, y \u001b[38;5;241m+\u001b[39m h\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# initialize the cascade for detection\n",
    "face_cascade = cv2.CascadeClassifier()\n",
    "eyes_cascade = cv2.CascadeClassifier()\n",
    "# load the cascade face followed by eyes\n",
    "face_cascade.load(cv2.samples.findFile(face_cascade_name))\n",
    "eyes_cascade.load(cv2.samples.findFile(eyes_cascade_name))\n",
    "camera_device = 0\n",
    "# enable video processing\n",
    "capture_cam_img = cv2.VideoCapture(camera_device)\n",
    "\n",
    "#enable classifier to operate on the face\n",
    "if capture_cam_img.isOpened:\n",
    "    while True:\n",
    "        ret, frame = capture_cam_img.read()\n",
    "        detect_face_eye(frame)\n",
    "        #shut down cv video sensing when ESC is pressed\n",
    "        if cv2.waitKey(10) == 27:\n",
    "            cv2.destroyAllWindows()\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe6fb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_face_eye(frame):\n",
    "    #normalization and convert color to gray scale\n",
    "    frame_to_gray = cv2.equalizeHist(cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY))\n",
    "    # application should be able to different scales of images\n",
    "    detected_faces = face_cascade.detectMultiScale(frame_to_gray)\n",
    "    for(x,y,w,h) in detected_faces:\n",
    "        center_face= (x + w//2, y + h//2)\n",
    "        #draw and ellipse\n",
    "        frame = cv2.ellipse(frame, center_face,(w//2, h//2),0,0,360,(125,125,125),6)\n",
    "        face_regionofinterest = frame_to_gray[y:y+h,x:x+w]\n",
    "        # detect eyes for each detected face\n",
    "        detected_eyes = eyes_cascade.detectMultiScale(face_regionofinterest)\n",
    "        for (x2,y2,w2,h2) in detected_eyes:\n",
    "            center_eye = (x + x2 + w2//2, y+y2+ h2//2)\n",
    "            radius = int(round(w2 + h2)* 0.25)\n",
    "            #draw circle\n",
    "            frame = cv2.circle(frame, center_eye, radius,(255,255,255),4)\n",
    "            \n",
    "cv2.imshow('--Face Detection--',frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99396a97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
